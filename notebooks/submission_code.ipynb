{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "target_features = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X_train = train.drop(['id'] + target_features, axis=1)\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "\n",
    "y_train = train[target_features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "features = X_train.columns\n",
    "\n",
    "# Create a column transformer for one-hot encoding and standard scaling\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a pipeline with the preprocessor and the model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', MultiOutputClassifier(CatBoostClassifier(random_seed=42, verbose=0)))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# make probability predictions\n",
    "preds = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87555497, 0.12444503])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If `preds` is a list of arrays (for models like RandomForest), we need to extract the positive class probabilities (class=1).\n",
    "# If your model returns a single array, this step can be skipped.\n",
    "if isinstance(preds, list):\n",
    "    preds = np.column_stack([p[:, 1] for p in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the RMSLE\n",
    "train_preds = pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pastry - AUC=0.7173\n",
      "Z_Scratch - AUC=0.9104\n",
      "K_Scatch - AUC=0.9693\n",
      "Stains - AUC=0.9974\n",
      "Dirtiness - AUC=0.7763\n",
      "Bumps - AUC=0.7616\n",
      "Other_Faults - AUC=0.7234\n",
      "Final Average AUC=0.8365\n"
     ]
    }
   ],
   "source": [
    "# Calculate the AUC score for each of the 7 classes\n",
    "auc_scores = []\n",
    "for i, col in enumerate(target_features):\n",
    "    # For Random Forest or any tree-based model, `predict_proba` returns a list of arrays\n",
    "    # Extract the probabilities of the positive class (index=1) for each class\n",
    "    if isinstance(preds, list):\n",
    "        auc = roc_auc_score(y_train[:, i], train_preds[i][:, 1])\n",
    "    else:\n",
    "        auc = roc_auc_score(y_train[:, i], train_preds[:, i])\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"{col} - AUC={auc:.4f}\")\n",
    "\n",
    "# Final average AUC score\n",
    "final_score = np.mean(auc_scores)\n",
    "print(f\"Final Average AUC={final_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id']\n",
    "})\n",
    "\n",
    "submission[target_features] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission is successfully saved!\n"
     ]
    }
   ],
   "source": [
    "# Save the submission file\n",
    "submission.to_csv('../output/submission.csv', index=False)\n",
    "print(\"Submission is successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
